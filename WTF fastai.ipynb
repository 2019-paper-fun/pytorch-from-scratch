{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./shakespeare.txt', <http.client.HTTPMessage at 0x7fbbf94f1860>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve(\"http://www.gutenberg.org/files/100/100-0.txt\", f'./shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = open('./shakespeare.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = text.replace('\\n', '').replace('\\t', '').replace('æ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im thou art bright,And dost him grace when clouds do blot the heaven:So flatter I the swart-complexioned night,When sparkling stars twire not thou gild’st the even.  But day doth daily draw my sorrows'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[20000:20200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 97\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !\"#$%&\\'()*,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]_`abcdefghijklmnopqrstuvwxyz|}Æà—‘’“”\\ufeff'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 44, 77, 74, 69, 64, 62, 79, 0, 35, 80, 79, 64, 73, 61, 64, 77, 66, 92, 78]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffProject Gutenberg’s'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_dat = [idx[i]   for i in range(0, len(idx)-3, 3)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-3, 3)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-3, 3)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-3, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([95, 74, 62, 35]), array([44, 69, 79, 80]), array([77, 64,  0, 79]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "embedding_length = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = Variable(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(vocab_size, embedding_length).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self, dset, bs=1):\n",
    "        self.dset = torch.LongTensor(dset).cuda()\n",
    "        self.len = len(self.dset)\n",
    "        self.idx = 0\n",
    "        self.bs = bs\n",
    "    def __len__(self):\n",
    "        return len(self.dset)\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        batch = [t for t in [torch.LongTensor(s.T).cuda() for s in np.stack([self.dset[i] for i in range(self.idx, self.idx + self.bs)]).T]] \n",
    "        self.idx = self.idx + self.bs\n",
    "        if self.idx > self.len - self.bs:\n",
    "            raise StopIteration\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Just for demo purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  95\n",
       "  74\n",
       " [torch.cuda.LongTensor of size 2 (GPU 0)], \n",
       "  44\n",
       "  69\n",
       " [torch.cuda.LongTensor of size 2 (GPU 0)], \n",
       "  77\n",
       "  64\n",
       " [torch.cuda.LongTensor of size 2 (GPU 0)], \n",
       "  74\n",
       "  62\n",
       " [torch.cuda.LongTensor of size 2 (GPU 0)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = DataGenerator(np.stack([x1,x2,x3,y], axis=1), bs=2)\n",
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-4.6944 -4.5044 -4.4879 -4.6572 -4.7816 -4.7845 -4.6319 -4.7057 -4.3343 -4.5623\n",
      "-4.5793 -4.5071 -4.4632 -4.8201 -5.0781 -4.6080 -4.8487 -4.7772 -4.5044 -4.6866\n",
      "\n",
      "Columns 10 to 19 \n",
      "-4.7588 -4.5446 -4.7652 -4.4265 -4.8748 -4.4213 -4.5453 -4.7087 -4.5867 -4.6358\n",
      "-4.5429 -4.6383 -4.5555 -4.4805 -4.6145 -4.5346 -4.8363 -4.7398 -4.4736 -4.4661\n",
      "\n",
      "Columns 20 to 29 \n",
      "-4.2845 -4.6128 -4.6387 -4.8540 -4.5047 -4.6851 -4.4222 -4.7024 -4.8334 -4.6780\n",
      "-4.4980 -4.6362 -4.5134 -4.6189 -4.5550 -4.7069 -4.4872 -4.6678 -4.8293 -4.7159\n",
      "\n",
      "Columns 30 to 39 \n",
      "-4.6676 -4.4244 -4.6224 -4.4371 -4.8172 -4.6989 -4.4100 -4.5136 -4.5534 -4.5819\n",
      "-4.4216 -4.7453 -4.5410 -4.6807 -4.5857 -4.8709 -4.5449 -4.6125 -4.7540 -4.5782\n",
      "\n",
      "Columns 40 to 49 \n",
      "-4.1439 -4.3563 -4.4975 -4.7177 -4.4925 -4.7223 -4.3293 -4.5946 -4.7192 -4.6504\n",
      "-4.3292 -4.0720 -4.5959 -4.7095 -4.5451 -4.6388 -4.6203 -4.7527 -4.7691 -4.4073\n",
      "\n",
      "Columns 50 to 59 \n",
      "-4.6581 -4.7156 -4.8316 -4.4920 -4.7279 -4.3553 -4.5645 -4.2831 -4.4928 -4.4991\n",
      "-4.4922 -4.3722 -4.5147 -4.2073 -4.6149 -4.3669 -4.8713 -4.3985 -4.1732 -4.6766\n",
      "\n",
      "Columns 60 to 69 \n",
      "-4.6233 -4.4468 -4.6684 -4.7144 -4.6024 -4.6774 -4.6742 -4.2011 -4.5829 -4.5189\n",
      "-4.4389 -4.4476 -4.5205 -4.6343 -4.5023 -4.6164 -4.4175 -4.4604 -4.4782 -4.6675\n",
      "\n",
      "Columns 70 to 79 \n",
      "-4.6289 -4.7646 -4.6589 -4.8684 -4.4672 -4.4844 -4.7430 -4.6214 -4.8010 -4.6696\n",
      "-4.6642 -4.5853 -4.7285 -4.7281 -4.4637 -4.7442 -4.6735 -4.6354 -4.7278 -4.6851\n",
      "\n",
      "Columns 80 to 89 \n",
      "-4.6297 -4.4742 -4.3395 -4.5874 -4.2409 -4.7179 -4.7825 -4.4437 -4.6812 -4.4716\n",
      "-4.5079 -4.7534 -4.3767 -4.6109 -4.4838 -5.0606 -4.6404 -4.6355 -4.5106 -4.7351\n",
      "\n",
      "Columns 90 to 96 \n",
      "-4.6069 -4.5950 -4.5074 -4.5028 -4.5328 -4.6671 -4.5187\n",
      "-4.5325 -4.6543 -4.2384 -4.5379 -4.4272 -4.4886 -4.6066\n",
      "[torch.cuda.FloatTensor of size 2x97 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "it = DataGenerator(np.stack([x1,x2,x3,y], axis=1), bs=2)\n",
    "*Xs, yt = next(it)\n",
    "t = model(*[Variable(x) for x in Xs])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.4512\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "\n",
      " 2.4202\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "\n",
      " 2.4117\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "\n",
      " 2.3916\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "\n",
      " 2.3848\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    stacked_training_data = DataGenerator(np.stack([x1,x2,x3,y], axis=1), bs=1024)\n",
    "    i = 0\n",
    "    loss = 0\n",
    "    for *X, Y in stacked_training_data:\n",
    "        i = i + 1\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(*[Variable(x) for x in X])\n",
    "        loss = F.nll_loss(y_pred, Variable(Y, requires_grad=False))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = torch.LongTensor(np.array([char_indices[c] for c in inp])).cuda()\n",
    "    p = model(*Variable(idxs))\n",
    "    i = np.argmax(p.data)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ye with the with the with the with the with the with the with the with the with the with the with the w'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('ye ', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
